{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GDey7DfCPz3b"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/flowers'\n",
        "print(f\"Updated base_dir to: {base_dir}\")"
      ],
      "metadata": {
        "id": "xsjNJX-cQenr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import tensorflow\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense,Flatten,Dropout,Activation\n",
        "\n",
        "import os\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/flowers'\n",
        "img_size = 224\n",
        "batch_size = 64\n",
        "\n",
        "# Check if the base directory exists\n",
        "if not os.path.exists(base_dir):\n",
        "    print(f\"Error: The directory '{base_dir}' does not exist. Please ensure Google Drive is mounted and the path is correct.\")\n",
        "else:\n",
        "    # create a data Augmentator\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255,zoom_range=0.2,horizontal_flip=True,validation_split=0.2)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
        "\n",
        "    # Creating the datasets\n",
        "\n",
        "    train_datagen = train_datagen.flow_from_directory(base_dir,\n",
        "                                                    target_size=(img_size,img_size),\n",
        "                                                    subset='training',\n",
        "                                                    batch_size=batch_size\n",
        "                                                    )\n",
        "\n",
        "    test_datagen = test_datagen.flow_from_directory(base_dir,\n",
        "                                                    target_size=(img_size,img_size),\n",
        "                                                    subset='validation',\n",
        "                                                    batch_size=batch_size\n",
        "                                                    )\n",
        "\n",
        "    #Model Dveelopment\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=64,kernel_size=(5,5),padding='same',activation='relu',input_shape=(224,224,3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(filters=32,kernel_size=(5,5),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(filters=16,kernel_size=(5,5),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(filters=8,kernel_size=(5,5),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512,activation='relu'))\n",
        "    model.add(Dense(5,activation='softmax')) # Changed activation to softmax\n",
        "\n",
        "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_datagen,epochs=5,validation_data=test_datagen)\n"
      ],
      "metadata": {
        "id": "m64--krIQ0oS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "_h1Rdx1nQ0lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = list(train_datagen.class_indices.keys())\n",
        "\n",
        "def predict_image(img):\n",
        "    # Resize the image to the model's expected input size\n",
        "    img = img.resize((img_size, img_size))\n",
        "    # Convert the image to a NumPy array\n",
        "    img_array = np.array(img)\n",
        "    # Normalize pixel values to the range [0, 1]\n",
        "    img_array = img_array / 255.0\n",
        "    # Add a batch dimension (e.g., from (224, 224, 3) to (1, 224, 224, 3))\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Make prediction\n",
        "    predictions = model.predict(img_array)\n",
        "    # Get the index of the predicted class\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "    # Get the class name\n",
        "    predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "    return predicted_class_name\n",
        "\n",
        "print(\"Predict function 'predict_image' defined successfully.\")\n",
        "print(f\"Class names extracted from train_datagen: {class_names}\")"
      ],
      "metadata": {
        "id": "uTFORJf9Q0jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface(\n",
        "    fn=predict_image,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Upload Image\"),\n",
        "    outputs=gr.Textbox(label=\"Predicted Class\"),\n",
        "    title=\"Flower Image Classifier\",\n",
        "    description=\"Upload an image of a flower to get its predicted class (daisy, lily, rose, sunflower, or tulips).\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True, share=True)\n",
        "print(\"Gradio interface launched successfully.\")"
      ],
      "metadata": {
        "id": "T6wl_ohQQ0fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DLsz2VB2Q0dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJz67vNbQ0ak"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}